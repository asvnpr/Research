{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pylab\n",
    "import wave\n",
    "import openpyxl\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "import _pickle as cpl # import cPickle\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this notebook, we declare functions to obtain a dataset from an Excel ROI file.  \n",
    "Dataset will be a dictionary of form:  \n",
    "{\n",
    "species:  \n",
    "    {  \n",
    "        min_freqs:[list]  \n",
    "        max_freqs:[list]  \n",
    "        start_time:[list]  \n",
    "        end_time:[list]  \n",
    "        recording name:[list]  \n",
    "    }  \n",
    "    ...  \n",
    "}  \n",
    "We also have a function to create a simplified dataset of form:\n",
    "{  \n",
    "species:  \n",
    "    {  \n",
    "        min_freq:val  \n",
    "        max_freq:val  \n",
    "        avg_time:val  \n",
    "        recording name:[list]  \n",
    "    }  \n",
    "    ...  \n",
    "}  \n",
    "     \n",
    "We will save these dictionaries as yaml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def wavInfo(rec_file):\n",
    "    wav_file = wave.open(rec_file, 'r')\n",
    "    frames = wav_file.readframes(-1)\n",
    "    wave_info = pylab.fromstring(frames, 'Int16') #all .wavs in our dataset are 16bit\n",
    "    framerate = wav_file.getframerate()\n",
    "    wav_file.close()\n",
    "    return wave_info, framerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get info. don't graph\n",
    "def specInfo(rec_file):\n",
    "    wave_info, framerate = wavInfo(rec_file)\n",
    "    spectrum, freqs, t, _ = pylab.specgram(wave_info, NFFT=512, noverlap=256, window=pylab.window_hanning, Fs=framerate)\n",
    "    del _\n",
    "    return spectrum, freqs, t\n",
    "    #pylab.savefig(\"%s_spectrogram.png\" % rec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# search for the index of the leftmost value in an ordered array \n",
    "# (of times or frequencies in our case) that still meet our criteria\n",
    "def leftmostBinSearch(A, lo, hi, target):\n",
    "    mid = (lo + hi) // 2\n",
    "    v1 = A[mid]\n",
    "    if (v1 >= target):\n",
    "        if (mid > 0 and A[mid - 1] > target):\n",
    "            return leftmostBinSearch(A, lo, mid-1, target)\n",
    "        else:\n",
    "            return mid\n",
    "    elif (A[mid] < target):\n",
    "        return leftmostBinSearch(A, mid+1, hi, target)\n",
    "    else:\n",
    "        return leftmostBinSearch(A, lo, mid-1, target)\n",
    "\n",
    "# search for the index of the rightmost value in an ordered array \n",
    "# (of times or frequencies in our case) that still meet our criteria\n",
    "def rightmostBinSearch(A, lo, hi, target): # something is wrong and it's giving me 1 to the right \n",
    "    mid = (lo + hi) // 2\n",
    "    v1 = A[mid]\n",
    "    if (v1 <= target):\n",
    "        if (mid < (len(A) - 1) and A[mid + 1] <= target):\n",
    "            return rightmostBinSearch(A, mid+1, hi, target)\n",
    "        else:\n",
    "            return mid\n",
    "    elif (A[mid] < target):\n",
    "        return rightmostBinSearch(A, mid+1, hi, target)\n",
    "    else:\n",
    "        return rightmostBinSearch(A, lo, mid-1, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getBounds(A, minVal, maxVal):\n",
    "    left = leftmostBinSearch(A, 0, len(A)-1, minVal)\n",
    "    right = rightmostBinSearch(A, 0, len(A)-1, maxVal)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get modified spectrum of frequencies and times that matter to us\n",
    "def specMod(spectrum, freqs, times, f1, f2, t1, t2):\n",
    "    spectrumMod = [spectrum[f1][t1:t2]]\n",
    "    for f in range(f1+1, f2): # check when fix right limit\n",
    "            spectrumMod = spectrumMod + [spectrum[f][t1:t2]]\n",
    "    return spectrumMod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# based off: http://stackoverflow.com/questions/15961979/how-do-i-plot-a-spectrogram-the-same-way-that-pylabs-specgram-does\n",
    "# plot the spectrogram of our region of interest\n",
    "def plotModSpecSimple(specMod, freqs, times, file):\n",
    "    \n",
    "    fig, ax = pylab.subplots(1)\n",
    "    pylab.pcolormesh(times, freqs, 10 * pylab.log10(specMod))\n",
    "    fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    pylab.savefig(file)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def speciesData(workbook):\n",
    "    roi_ws = openpyxl.load_workbook(workbook)['ROIs'] # should change accordingly to where and how you data is stored\n",
    "    dataset = {}\n",
    "    # needed format:\n",
    "    # species specimen per row\n",
    "    # columns: species name, start_time, end_time, min_freq, max_freq, recording name\n",
    "    # columns A to F\n",
    "    sheetMatrix = list(roi_ws.iter_rows())\n",
    "    # remove row with column names and create array of keys per species. (e.g. start_time, end_time, ...)\n",
    "    keys = sheetMatrix.pop(0) \n",
    "    for row in sheetMatrix:\n",
    "        speciesName = row[0].value\n",
    "        if (speciesName not in dataset):\n",
    "            dataset[speciesName] = {}\n",
    "        for col in range(1,len(row)):\n",
    "            cell = ''\n",
    "            # change recording extension since we are dealing with wav files\n",
    "            if (col == 5):\n",
    "                cell = row[col].value.split('.')[0]\n",
    "                cell += '.wav'\n",
    "            else:\n",
    "                cell = row[col].value\n",
    "            # if per species key is not present add the key and add the value as the first element in a list\n",
    "            if (keys[col].value not in dataset[speciesName]): \n",
    "                dataset[speciesName][keys[col].value] = [cell]\n",
    "            # append to the list of attributes \n",
    "            else:\n",
    "                dataset[speciesName][keys[col].value] = dataset[speciesName][keys[col].value] + [cell]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dataToYAML(data, name): # convert speciesData dictionary to yaml and save file\n",
    "    # need to check if file exists then delete it\n",
    "    path = '../dataset/' + name\n",
    "    dataset = open(path, 'w+')\n",
    "    dump = yaml.dump(data, dataset, default_flow_style=False)\n",
    "    dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def findMax(L):\n",
    "    Max = float('-inf')\n",
    "    for n in L:\n",
    "        if (n > Max):\n",
    "            Max = n\n",
    "    return Max\n",
    "\n",
    "def findMin(L):\n",
    "    Min = float('inf')\n",
    "    for n in L:\n",
    "        if (n < Min):\n",
    "            Min = n\n",
    "    return Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#need to decide if exceed bounds of spectrograms or restrict\n",
    "# WIP. time data is wrong. need to find average time duration\n",
    "def simplifiedSpeciesData(data): \n",
    "    simplDat = {}\n",
    "    for species in data:\n",
    "        min_freqs = data[species]['min_frequency']\n",
    "        max_freqs = data[species]['max_frequency']\n",
    "        min_times = data[species]['start_time']\n",
    "        max_times = data[species]['end_time']\n",
    "        min_f = findMin(min_freqs)\n",
    "        max_f = findMax(max_freqs)\n",
    "        start = findMin(min_times)\n",
    "        end = findMax(max_times)\n",
    "        simplDat[species] = {'min_freq':min_f, 'max_freq':max_f, 'delta_time':(end - start), 'recording name':data[species]['recording name']}\n",
    "    return simplDat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save our species data dictionary as a .yaml file for later use\n",
    "workbook = '../dataset/validationsAndROIs.xlsx'\n",
    "data = speciesData(workbook)\n",
    "dataToYAML(data, 'dataset.yaml')\n",
    "#simpleData = simplifiedSpeciesData(data)\n",
    "#dataToYAML(simpleData, 'simplifiedDataset.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use our previous functions to go through our generated dictionary and create a  \n",
    "Raw unprocessed dataset of spectrogram of ROIs in appropriate directories per species  \n",
    "and returning our dataset as a 2D array of dictionaries that contain our images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getRawSpecDataset(dataset, path='../dataset'):\n",
    "    \n",
    "    # make directory to store our spec dataset\n",
    "    dataset_path = path + '/spectrogram_roi_dataset'\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.makedirs(dataset_path)\n",
    "    else:\n",
    "        shutil.rmtree(dataset_path)\n",
    "        os.makedirs(dataset_path)\n",
    "    species = dataset.keys()\n",
    "    \n",
    "    # image data to be pickled \n",
    "    specs = []\n",
    "    \n",
    "    for s in species:\n",
    "        s_dir = dataset_path + '/' + s\n",
    "        s_spec = []\n",
    "        os.makedirs(s_dir) # make a directory per species\n",
    "        \n",
    "        # load species ROI data\n",
    "        min_freqs = dataset[s]['min_frequency']\n",
    "        max_freqs = dataset[s]['max_frequency']\n",
    "        starts = dataset[s]['start_time']\n",
    "        ends = dataset[s]['end_time']\n",
    "        recs = dataset[s]['recording name']\n",
    "        \n",
    "        for i in range(0, len(recs)):\n",
    "            rec = '../dataset/recordings/' + recs[i] # path to ith recording file where s is present\n",
    "            spectrum, freqs, times = specInfo(rec) # get entire spectrogram data from rec\n",
    "            \n",
    "            # get ROI info in rec\n",
    "            t_0 = starts[i] \n",
    "            t_n = ends[i]\n",
    "            f_0 = min_freqs[i]\n",
    "            f_n = max_freqs[i]\n",
    "            \n",
    "            # find closest times and freqs that match ROI info\n",
    "            t_start, t_end = getBounds(times, t_0, t_n)\n",
    "            f_start, f_end = getBounds(freqs, f_0, f_n)\n",
    "            \n",
    "            # get modified spectrum, freqs, and times\n",
    "            spectrumMod = specMod(spectrum, freqs, times, f_start, f_end, t_start, t_end)\n",
    "            freqMod = freqs[f_start:f_end]\n",
    "            timeMod = times[t_start:t_end]\n",
    "            filename = s_dir + '/' + s + '_spec_' + str(i+1) + '.png'\n",
    "            \n",
    "            # plot the spectrogram of ROI and save the image \n",
    "            f = plotModSpecSimple(spectrumMod, freqMod, timeMod, filename)\n",
    "            s_spec.append(f) # append image to list of ROI spectrograms per species\n",
    "            pylab.close\n",
    "        \n",
    "        # add dictionary with key <species_name> and value <list_of_spectrogram_figures>\n",
    "        specs.append({s:s_spec}) \n",
    "    \n",
    "    return specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:4: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "/usr/local/lib/python3.6/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "yamlData = open('../dataset/dataset.yaml', 'r')\n",
    "dataset = yaml.load(yamlData)\n",
    "yamlData.close()\n",
    "data = getRawSpecDataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll package our dataset in a more manageble format by:  \n",
    "* archiving and compressing our dataset directory into a .tar.bz2 file\n",
    "* serializing our dataset object into a folder of pickles (was recieving errors when  \n",
    "  I tried to serialize the whole object. maybe too big?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def serializeDataset(obj, path='../dataset'):\n",
    "    pickle_path = path + '/pickle_data'\n",
    "    # create pickle directory if exists, else overwrite it\n",
    "    if not os.path.exists(pickle_path):\n",
    "        os.makedirs(pickle_path)\n",
    "    else:\n",
    "        shutil.rmtree(pickle_path)\n",
    "        os.makedirs(pickle_path)\n",
    "    for s in obj:\n",
    "        species = list(s.keys())[0]\n",
    "        data = s[species]\n",
    "        picklename = pickle_path + '/' + species + '.pickle'\n",
    "        with open(picklename, 'wb+') as pn:\n",
    "            cpl.dump(data, pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "serializeDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def archiveAndCompress(path):\n",
    "    directory = path.split('/')[0:-1]\n",
    "    directory = '/'.join(directory)\n",
    "    archive_name = directory + '/' + path.split('/')[-1] + '.tar.bz2'\n",
    "    with tarfile.open(archive_name, 'w:bz2') as archive:\n",
    "        folder = os.listdir(path)\n",
    "        for f in folder:\n",
    "            f = path + '/' + f\n",
    "            archive.add(f, arcname=os.path.basename(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "archiveAndCompress('../dataset/spectrogram_roi_dataset')\n",
    "archiveAndCompress('../dataset/pickle_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running these functions should result in:\n",
    "* .yaml file that contains the structure of our dataset\n",
    "* a spectrogram_roi_dataset directory that contains directories of species and their ROI spectrograms\n",
    "* a spectrogram_roi_dataset.tar.bz2\n",
    "* a pickle_data direcrory that contains a pickle of the ROI spectrograms of each species\n",
    "* a pickle_data.tar.bz2  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
